# -*- coding: utf-8 -*-
"""Copy of Auto_EDA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19xlKLZNqEDuiI4BsMrflr-mRDktpX_nh
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px
from scipy.stats import skew
from scipy.stats import kurtosis
from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, Normalizer
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
import warnings
warnings.filterwarnings('ignore')

#/content/layoffs_data.csv, since im using colab im using this path
path = input("Please enter the path where you have stored your csv file:")
#path = path.replace("\\","/")
path

df = pd.read_csv(path)
df

shape = df.shape
shape

dimentions = df.ndim
dimentions

size = df.size
size

summary = df.describe()
summary

info = df.info()
info

columns = df.columns
columns

n_col = len(columns)
n_col

types = df.dtypes
types

unique = df.nunique()
unique

duplicates = df.duplicated().sum()
duplicates

d_p = duplicates/len(df)*100
d_p

missing = df.isnull().sum()
missing

m_p = missing/len(df)*100
m_p

num = df.select_dtypes(exclude = 'object')
num

cat = df.select_dtypes(include = 'object',exclude='datetime')
cat

date = df.select_dtypes(include=['datetime' ,'datetime64'])
date

n_num = num.shape[1]
n_num

n_cat = cat.shape[1]
n_cat

correlation = df.corr(numeric_only=True)
correlation

"""
· If the skewness is between -0.5 and 0.5, the data are fairly symmetrical

· If the skewness is between -1 and — 0.5 or between 0.5 and 1, the data are moderately skewed

· If the skewness is less than -1 or greater than 1, the data are highly skewed
"""
def predict_skewness(df):

    numeric_df = df.select_dtypes(include=['number'])

    if numeric_df.empty:
        print("No numeric columns found in the DataFrame.")
        return

    for col in numeric_df.columns:
        print(f"\nProcessing column for calculating skewness: {col}")

        skewness_value = skew(numeric_df[col].dropna())  # Dropping NaN to avoid skew calculation issues
        print(f"Skewness of '{col}': {skewness_value}")

        if skewness_value > 1:
            print(f"'{col}' is Highly Positively Skewed(Right Skewed).")
        elif 0.5 < skewness_value <= 1:
            print(f"'{col}' is Moderately Positively Skewed.")
        elif -0.5 <= skewness_value <= 0.5:
            print(f"'{col}' is Approximately Symmetric.")
        elif -1 <= skewness_value < -0.5:
            print(f"'{col}' is Moderately Negatively Skewed(Left Skewed).")
        else:
            print(f"'{col}' is Highly Negatively Skewed.")

predict_skewness(df)

"""
· High kurtosis in a data set is an indicator that data has heavy outliers.

· Low kurtosis in a data set is an indicator that data has lack of outliers.

A kurtosis value of -2 or less indicates a platykurtic distribution, which is flatter than a normal distribution.
A kurtosis value of zero indicates a mesokurtic distribution, which is similar to a normal distribution.
A kurtosis value between zero and 2 indicates a leptokurtic distribution, which is more peaked than a normal distribution.
A kurtosis value above 2 indicates an extremely leptokurtic distribution.infinity.
"""
def predict_kurtosis(df):

    numeric_df = df.select_dtypes(include=['number'])


    if numeric_df.empty:
        print("No numeric columns found in the DataFrame.")
        return

    for col in numeric_df.columns:
        print(f"\nProcessing column for kurtosis calculation: {col}")

        kurtosis_value = kurtosis(numeric_df[col].dropna())  # Dropping NaN to avoid calculation issues
        print(f"Kurtosis of '{col}': {kurtosis_value}")

        if kurtosis_value > 0:
            print(f"'{col}' is Leptokurtic (heavy tails of outliers).")
        elif kurtosis_value == 0:
            print(f"'{col}' is Mesokurtic (normal distribution).")
        else:
            print(f"'{col}' is Platykurtic (light tails of outliers).")


predict_kurtosis(df)

def convert_data_types(df):
    print("Data Types of Original DataFrame:")
    print(df.dtypes)
    for col in df.columns:
        print(f"\nProcessing column: {col}")
        print("1: Convert to String")
        print("2: Convert to Integer")
        print("3: Convert to Float")
        print("4: Convert to Datetime")
        print("0: Do Nothing")

        choice = input("Enter your choice (1, 2, 3, 4, 0): ")

        if choice == '1':
            df[col] = df[col].astype(str)
            print(f"Column '{col}' converted to String.")

        elif choice == '2':
            try:
                df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int64')  # Handles NaN with integer conversion
                print(f"Column '{col}' converted to Integer.")
            except ValueError:
                print(f"Conversion of column '{col}' to Integer failed. Check data compatibility.")

        elif choice == '3':
            try:
                df[col] = pd.to_numeric(df[col], errors='coerce')
                print(f"Column '{col}' converted to Float.")
            except ValueError:
                print(f"Conversion of column '{col}' to Float failed. Check data compatibility.")

        elif choice == '4':
            try:
                df[col] = pd.to_datetime(df[col], errors='coerce')
                print(f"Column '{col}' converted to Datetime.")
            except ValueError:
                print(f"Conversion of column '{col}' to Datetime failed. Check data compatibility.")

        elif choice == '0':

            print(f"No operation applied to column '{col}'.")

        else:
            print("Invalid choice. No changes made.")

    return df

df = convert_data_types(df)
print("\nUpdated DataFrame:")
print(df)
print("\nData Types of Updated DataFrame:")
print(df.dtypes)

def handle_missing_values(df):
    for col in df.columns:
        if df[col].isnull().sum() > 0:
            print(f"\nProcessing column: {col}")
            print("1: Fill with Mean (numeric only)")
            print("2: Fill with Median (numeric only)")
            print("3: Fill with Mode")
            print("4: Fill with Ffill")
            print("5: Fill with Bfill")
            print("6: Fill with Linear")
            print("7: Fill with Polynomial")
            print("8: Fill with a Specific Value")
            print("9: Drop Rows with Missing Values")
            print("0: Do Nothing")

            choice = input("Enter your choice (1, 2, 3, 4, 5, 6, 7, 8, 9, 0): ")

            if choice == '1' and pd.api.types.is_numeric_dtype(df[col]):
                mean = df[col].mean()
                df[col].fillna(mean, inplace=True)
                print(f"Missing values in column '{col}' filled with mean: {mean}.")

            elif choice == '2' and pd.api.types.is_numeric_dtype(df[col]):
                median = df[col].median()
                df[col].fillna(median, inplace=True)
                print(f"Missing values in column '{col}' filled with median: {median}.")

            elif choice == '3':
                mode = df[col].mode().iloc[0]  # Fill with the first mode value
                df[col].fillna(mode, inplace=True)
                print(f"Missing values in column '{col}' filled with mode: {mode}.")

            elif choice == '4' :
                ffill = df[col].ffill()
                print(f"Missing values in column '{col}' filled with forward fill value {ffill}.")

            elif choice == '5':
                bfill = df[col].bfill()
                print(f"Missing values in column '{col}' filled with backward fill value {bfill}.")

            elif choice == '6':
                linear = df[col].interpolate(method='linear', inplace=True)
                print(f"Missing values in column '{col}' filled with linear value: {linear}.")

            elif choice == '7':
                poly = df[col].interpolate(method='polynomial',order=3 ,inplace=True)
                print(f"Missing values in column '{col}' filled with quadratic value : {poly}.")

            elif choice == '8':
                specific_value = input(f"Enter the specific value to fill missing values in column '{col}': ")
                df[col].fillna(specific_value, inplace=True)
                print(f"Missing values in column '{col}' filled with: {specific_value}.")

            elif choice == '9':
                df.dropna(subset=[col], inplace=True)
                print(f"Rows with missing values in column '{col}' dropped.")

            elif choice == '0':
                print(f"No operation applied to column '{col}'.")

            else:
                print("Invalid choice or operation not applicable for the column type. No changes made.")
        else:
            print(f"No missing values found in column '{col}'. Moving to the next column.")

    return df

df = handle_missing_values(df)
print("\nUpdated DataFrame:")
print(df)

df.isnull().sum()

px.box(df['Percentage'])

def handle_outliers(df):
    for col in df.columns:
        if pd.api.types.is_numeric_dtype(df[col]):
            print(f"\nProcessing column: {col}")
            print("1: Remove Outliers using IQR")
            print("2: Remove Outliers using Z-Score")
            print("0: Do Nothing")

            choice = input("Enter your choice (1, 2, 0): ")

            if choice == '1':
                Q1 = df[col].quantile(0.25)
                Q3 = df[col].quantile(0.75)
                IQR = Q3 - Q1
                lower = Q1 - 1.5 * IQR
                upper = Q3 + 1.5 * IQR
                df = df[(df[col] >= lower) & (df[col] <= upper)]
                print(f"Outliers removed from column '{col}' using IQR method.")

            elif choice == '2':
                mean = df[col].mean()
                std_dev = df[col].std()
                df = df[(df[col] - mean).abs() <= 3 * std_dev]
                print(f"Outliers removed from column '{col}' using Z-Score method.")

            elif choice == '0':
                print(f"No operation applied to column '{col}'.")
            else:
                print("Invalid choice. No changes made.")
        else:
            print(f"Column '{col}' is not numeric. Skipping outlier handling for this column.")

    return df


df = handle_outliers(df)
print("\nUpdated DataFrame:")
print(df)

px.box(df['Percentage'])

def scaling(df):
    for col in df.columns:
        if pd.api.types.is_numeric_dtype(df[col]):
            print(f"\nProcessing column: {col}")
            print("1: Min-Max Scaling (0 to 1 range)")
            print("2: Standard Scaling (mean=0, std=1)")
            print("3: Robust Scaling (using IQR)")
            print("4: Normalization (L2 norm)")
            print("0: Do Nothing")

            choice = input("Enter your choice (1, 2, 3, 4, 0): ")

            if choice == '1':
                scaler = MinMaxScaler()
                df[col] = scaler.fit_transform(df[[col]])
                print(f"Column '{col}' scaled using Min-Max Scaling.")

            elif choice == '2':
                scaler = StandardScaler()
                df[col] = scaler.fit_transform(df[[col]])
                print(f"Column '{col}' standardized using Standard Scaling (Z-score).")

            elif choice == '3':
                scaler = RobustScaler()
                df[col] = scaler.fit_transform(df[[col]])
                print(f"Column '{col}' scaled using Robust Scaling.")

            elif choice == '4':
                normalizer = Normalizer()
                df[col] = normalizer.fit_transform(df[[col]])
                print(f"Column '{col}' normalized using L2 norm.")

            elif choice == '0':
                print(f"No operation applied to column '{col}'.")
            else:
                print("Invalid choice. No changes made.")
        else:
            print(f"Column '{col}' is not numeric. Skipping scaling/standardizing for this column.")

    return df


df = scaling(df)
print("\nUpdated DataFrame:")
print(df)

df.corr(numeric_only=True)

def feature_engineering(df):
    for col in df.columns:
        print(f"\nProcessing column: {col}")
        if pd.api.types.is_numeric_dtype(df[col]):  # Numeric column options
            print("1: Bin Numerical Data")
            print("2: Apply Log Transformation")
            print("3: Apply Square Root Transformation")
            print("0: Do Nothing")

        elif pd.api.types.is_categorical_dtype(df[col]) or df[col].dtype == 'object':  # Categorical column options
            print("1: One-Hot Encoding")
            print("2: Label Encoding")
            print("0: Do Nothing")

        else:
            print("No operations available for this column type.")
            continue

        choice = input("Enter your choice (1, 2, 3, 4, 0): ")

        if pd.api.types.is_numeric_dtype(df[col]):
            if choice == '1':
                bins = int(input("Enter number of bins: "))
                labels = [f"Bin{i}" for i in range(1, bins + 1)]
                df[col + '_binned'] = pd.cut(df[col], bins=bins, labels=labels)
                print(f"Numerical data in column '{col}' binned into {bins} bins.")

            elif choice == '2':
                df[col + '_log'] = np.log1p(df[col])
                print(f"Log transformation applied to column '{col}'.")

            elif choice == '3':
                df[col + '_sqrt'] = np.sqrt(df[col])
                print(f"Square root transformation applied to column '{col}'.")




        elif pd.api.types.is_categorical_dtype(df[col]) or df[col].dtype == 'object':
            if choice == '1':
                one_hot_encoder = OneHotEncoder()
                encoded = one_hot_encoder.fit_transform(df[[col]])
                print(f"One-hot encoding applied to column '{col}'.")

            elif choice == '2':
                le = LabelEncoder()
                df[col] = le.fit_transform(df[col])
                print(f"Label encoding applied to column '{col}'.")

        elif choice == '0':
            print(f"No operation applied to column '{col}'.")
        else:
            print("Invalid choice. No changes made.")

    return df

df = feature_engineering(df)
print("\nUpdated DataFrame:")
print(df)

df

